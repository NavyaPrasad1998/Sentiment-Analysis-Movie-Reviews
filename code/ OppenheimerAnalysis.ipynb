{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "executionInfo": {
     "elapsed": 3970,
     "status": "ok",
     "timestamp": 1702638512108,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "VsVLSjnlKD6o"
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import re # for regex\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB,MultinomialNB,BernoulliNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 52974,
     "status": "ok",
     "timestamp": 1702638589889,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "gPfT1lgBKSkk",
    "outputId": "1037455d-632f-4838-c791-7573fce0a13c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                 Review Rating\n",
      "0     One of the most anticipated films of the year ...   8/10\n",
      "1     You'll have to have your wits about you and yo...   9/10\n",
      "2     I'm a big fan of Nolan's work so was really lo...   7/10\n",
      "3     \"Oppenheimer\" is a biographical thriller film ...  10/10\n",
      "4     This movie is just... wow! I don't think I hav...  10/10\n",
      "...                                                 ...    ...\n",
      "3532  Again the usa is shown as the good boys fighti...   1/10\n",
      "3533  An honest view from a good fan of Nolan's work...   5/10\n",
      "3534  I discovered this film to be excessively intri...   5/10\n",
      "3535  Had so high expectations. Wanted something spe...   4/10\n",
      "3536  Movie is deprived of any emotion, script is em...   1/10\n",
      "\n",
      "[3537 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "start_url = 'https://www.imdb.com/title/tt15398776/reviews/?ref_=tt_ql_2'\n",
    "link = 'https://www.imdb.com/title/tt15398776/reviews/_ajax'\n",
    "\n",
    "params = {\n",
    "    'ref_': 'undefined',\n",
    "    'paginationKey': ''\n",
    "}\n",
    "\n",
    "reviews_list = []\n",
    "\n",
    "with requests.Session() as s:\n",
    "    s.headers['User-Agent'] = 'Mozilla/5.0 (Windows NT 6.1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/88.0.4324.150 Safari/537.36'\n",
    "    res = s.get(start_url)\n",
    "\n",
    "    while True:\n",
    "        soup = BeautifulSoup(res.text, \"lxml\")\n",
    "        for item in soup.select(\".review-container\"):\n",
    "            review_text = item.select_one(\".text.show-more__control\").get_text(strip=True)\n",
    "            rating = item.select_one(\".ipl-ratings-bar\").text.strip() if item.select_one(\".ipl-ratings-bar\") else None\n",
    "            reviews_list.append({'Review': review_text, 'Rating': rating})\n",
    "\n",
    "        try:\n",
    "            pagination_key = soup.select_one(\".load-more-data[data-key]\").get(\"data-key\")\n",
    "        except AttributeError:\n",
    "            break\n",
    "        params['paginationKey'] = pagination_key\n",
    "        res = s.get(link, params=params)\n",
    "\n",
    "# Convert the list of reviews into a DataFrame\n",
    "df = pd.DataFrame(reviews_list)\n",
    "\n",
    "# Print the DataFrame\n",
    "print(df)\n",
    "\n",
    "# Optionally, you can save the DataFrame to a CSV file\n",
    "df.to_csv('oppen_reviews.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 449,
     "status": "ok",
     "timestamp": 1702638593545,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "-_sKZCNXKkcp",
    "outputId": "a7d9a3da-4a58-4d52-bbd9-3a7e36f5d1f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /Users/navyaprasad/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('vader_lexicon')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "executionInfo": {
     "elapsed": 10325,
     "status": "ok",
     "timestamp": 1702638606550,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "0R3tiI0rKnXI"
   },
   "outputs": [],
   "source": [
    "# Initialize the sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Define a function to get the sentiment of a review\n",
    "def get_sentiment(review):\n",
    "    sentiment = sia.polarity_scores(review)\n",
    "    return sentiment['compound']  # return the compound score which is a single number representing the sentiment\n",
    "\n",
    "# Apply the function to the 'Review' column of the DataFrame\n",
    "df['Sentiment'] = df['Review'].apply(get_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating'] = df['Rating'].str.extract('(\\d+)')\n",
    "\n",
    "# Convert the 'Rating' column to numeric\n",
    "df['Rating'] = pd.to_numeric(df['Rating'], errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Rating_Sentiment_Product'] = df['Rating'] * df['Sentiment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Sentiment_Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>7.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>8.9118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>5.7806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>9.9870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>9.9080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment  \\\n",
       "0  One of the most anticipated films of the year ...     8.0     0.9975   \n",
       "1  You'll have to have your wits about you and yo...     9.0     0.9902   \n",
       "2  I'm a big fan of Nolan's work so was really lo...     7.0     0.8258   \n",
       "3  \"Oppenheimer\" is a biographical thriller film ...    10.0     0.9987   \n",
       "4  This movie is just... wow! I don't think I hav...    10.0     0.9908   \n",
       "\n",
       "   Rating_Sentiment_Product  \n",
       "0                    7.9800  \n",
       "1                    8.9118  \n",
       "2                    5.7806  \n",
       "3                    9.9870  \n",
       "4                    9.9080  "
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(subset=['Rating_Sentiment_Product'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Sentiment_Product</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>7.9800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>8.9118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>5.7806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>9.9870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>9.9080</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment  \\\n",
       "0  One of the most anticipated films of the year ...     8.0     0.9975   \n",
       "1  You'll have to have your wits about you and yo...     9.0     0.9902   \n",
       "2  I'm a big fan of Nolan's work so was really lo...     7.0     0.8258   \n",
       "3  \"Oppenheimer\" is a biographical thriller film ...    10.0     0.9987   \n",
       "4  This movie is just... wow! I don't think I hav...    10.0     0.9908   \n",
       "\n",
       "   Rating_Sentiment_Product  \n",
       "0                    7.9800  \n",
       "1                    8.9118  \n",
       "2                    5.7806  \n",
       "3                    9.9870  \n",
       "4                    9.9080  "
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3495 entries, 0 to 3536\n",
      "Data columns (total 4 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   Review                    3495 non-null   object \n",
      " 1   Rating                    3495 non-null   float64\n",
      " 2   Sentiment                 3495 non-null   float64\n",
      " 3   Rating_Sentiment_Product  3495 non-null   float64\n",
      "dtypes: float64(3), object(1)\n",
      "memory usage: 136.5+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a function to categorize based on the 'Rating_Sentiment_Product' column\n",
    "def categorize_combined(product):\n",
    "    if pd.isna(product):  \n",
    "        return 'Not Rated'\n",
    "\n",
    "    if product >= 8:\n",
    "        return 'Strong Positive'\n",
    "    elif product >= 6:\n",
    "        return 'Positive'\n",
    "    elif product >= 0:\n",
    "        return 'Neutral'\n",
    "    elif product >= -3:\n",
    "        return 'Negative'\n",
    "    else:\n",
    "        return 'Strong Negative'\n",
    "\n",
    "# Apply the categorization function to create a new column\n",
    "df['Sentiment_Category'] = df['Rating_Sentiment_Product'].apply(categorize_combined)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strong Positive    1465\n",
       "Neutral             807\n",
       "Positive            623\n",
       "Strong Negative     319\n",
       "Negative            281\n",
       "Name: Sentiment_Category, dtype: int64"
      ]
     },
     "execution_count": 296,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment_Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (0.11.0)\r\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.24.3)\r\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.10.1)\r\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\r\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[298], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Define the features and target variable\u001b[39;00m\n\u001b[1;32m      4\u001b[0m X \u001b[38;5;241m=\u001b[39m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mReview\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.over_sampling` provides a set of method to\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mperform over-sampling.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_random_over_sampler.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_X\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     23\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseOverSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRandomOverSampler\u001b[39;00m(BaseOverSampler):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "# Define the features and target variable\n",
    "X = data['Review']\n",
    "y = data['Sentiment_Category']\n",
    "\n",
    "# Initialize the oversampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Resample the data\n",
    "X_resampled, y_resampled = oversampler.fit_resample(X.values.reshape(-1, 1), y)\n",
    "\n",
    "# Create a new DataFrame with the resampled data\n",
    "balanced_data = pd.DataFrame({'Review': X_resampled.flatten(), 'Sentiment_Category': y_resampled})\n",
    "\n",
    "# Print the count of each unique value in the 'Sentiment_Category' column\n",
    "print(balanced_data['Sentiment_Category'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[280], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Assuming 'X' contains your feature columns, and 'y' contains your target column\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.over_sampling` provides a set of method to\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mperform over-sampling.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_random_over_sampler.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_X\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     23\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseOverSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRandomOverSampler\u001b[39;00m(BaseOverSampler):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'X' contains your feature columns, and 'y' contains your target column\n",
    "X = df[['Rating_Sentiment_Product']]\n",
    "y = df['Sentiment_Category']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize RandomOverSampler\n",
    "random_over_sampler = RandomOverSampler(random_state=42)\n",
    "\n",
    "# Fit and transform the training data using RandomOverSampler\n",
    "X_train_balanced, y_train_balanced = random_over_sampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Now, X_train_balanced and y_train_balanced have a balanced class distribution\n",
    "# You can use these for training your model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 338,
     "status": "ok",
     "timestamp": 1702638616009,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "j_QeP2N8KnbO",
    "outputId": "49794440-9e6d-4daa-abcf-4cae4f756622"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Sentiment_Product</th>\n",
       "      <th>Sentiment_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>7.9800</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>8.9118</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>5.7806</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>9.9870</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>9.9080</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review  Rating  Sentiment  \\\n",
       "0  One of the most anticipated films of the year ...     8.0     0.9975   \n",
       "1  You'll have to have your wits about you and yo...     9.0     0.9902   \n",
       "2  I'm a big fan of Nolan's work so was really lo...     7.0     0.8258   \n",
       "3  \"Oppenheimer\" is a biographical thriller film ...    10.0     0.9987   \n",
       "4  This movie is just... wow! I don't think I hav...    10.0     0.9908   \n",
       "\n",
       "   Rating_Sentiment_Product Sentiment_Category  \n",
       "0                    7.9800           Positive  \n",
       "1                    8.9118    Strong Positive  \n",
       "2                    5.7806            Neutral  \n",
       "3                    9.9870    Strong Positive  \n",
       "4                    9.9080    Strong Positive  "
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 423
    },
    "executionInfo": {
     "elapsed": 187,
     "status": "ok",
     "timestamp": 1702638640275,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "esZNFqV-Knks",
    "outputId": "85ac8c75-85ba-4d21-8dfc-e0cadf66ad22"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Rating_Sentiment_Product</th>\n",
       "      <th>Sentiment_Category</th>\n",
       "      <th>Combined_Features</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.9975</td>\n",
       "      <td>7.9800</td>\n",
       "      <td>Positive</td>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.9902</td>\n",
       "      <td>8.9118</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.8258</td>\n",
       "      <td>5.7806</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9987</td>\n",
       "      <td>9.9870</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.9908</td>\n",
       "      <td>9.9080</td>\n",
       "      <td>Strong Positive</td>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3532</th>\n",
       "      <td>Again the usa is shown as the good boys fighti...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.9115</td>\n",
       "      <td>-0.9115</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Again the usa is shown as the good boys fighti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3533</th>\n",
       "      <td>An honest view from a good fan of Nolan's work...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.9731</td>\n",
       "      <td>4.8655</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>An honest view from a good fan of Nolan's work...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3534</th>\n",
       "      <td>I discovered this film to be excessively intri...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.2391</td>\n",
       "      <td>1.1955</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>I discovered this film to be excessively intri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3535</th>\n",
       "      <td>Had so high expectations. Wanted something spe...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.3114</td>\n",
       "      <td>-1.2456</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Had so high expectations. Wanted something spe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3536</th>\n",
       "      <td>Movie is deprived of any emotion, script is em...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.5562</td>\n",
       "      <td>-0.5562</td>\n",
       "      <td>Negative</td>\n",
       "      <td>Movie is deprived of any emotion, script is em...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3495 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Review  Rating  Sentiment  \\\n",
       "0     One of the most anticipated films of the year ...     8.0     0.9975   \n",
       "1     You'll have to have your wits about you and yo...     9.0     0.9902   \n",
       "2     I'm a big fan of Nolan's work so was really lo...     7.0     0.8258   \n",
       "3     \"Oppenheimer\" is a biographical thriller film ...    10.0     0.9987   \n",
       "4     This movie is just... wow! I don't think I hav...    10.0     0.9908   \n",
       "...                                                 ...     ...        ...   \n",
       "3532  Again the usa is shown as the good boys fighti...     1.0    -0.9115   \n",
       "3533  An honest view from a good fan of Nolan's work...     5.0     0.9731   \n",
       "3534  I discovered this film to be excessively intri...     5.0     0.2391   \n",
       "3535  Had so high expectations. Wanted something spe...     4.0    -0.3114   \n",
       "3536  Movie is deprived of any emotion, script is em...     1.0    -0.5562   \n",
       "\n",
       "      Rating_Sentiment_Product Sentiment_Category  \\\n",
       "0                       7.9800           Positive   \n",
       "1                       8.9118    Strong Positive   \n",
       "2                       5.7806            Neutral   \n",
       "3                       9.9870    Strong Positive   \n",
       "4                       9.9080    Strong Positive   \n",
       "...                        ...                ...   \n",
       "3532                   -0.9115           Negative   \n",
       "3533                    4.8655            Neutral   \n",
       "3534                    1.1955            Neutral   \n",
       "3535                   -1.2456           Negative   \n",
       "3536                   -0.5562           Negative   \n",
       "\n",
       "                                      Combined_Features  \n",
       "0     One of the most anticipated films of the year ...  \n",
       "1     You'll have to have your wits about you and yo...  \n",
       "2     I'm a big fan of Nolan's work so was really lo...  \n",
       "3     \"Oppenheimer\" is a biographical thriller film ...  \n",
       "4     This movie is just... wow! I don't think I hav...  \n",
       "...                                                 ...  \n",
       "3532  Again the usa is shown as the good boys fighti...  \n",
       "3533  An honest view from a good fan of Nolan's work...  \n",
       "3534  I discovered this film to be excessively intri...  \n",
       "3535  Had so high expectations. Wanted something spe...  \n",
       "3536  Movie is deprived of any emotion, script is em...  \n",
       "\n",
       "[3495 rows x 6 columns]"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[258], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m TfidfVectorizer\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.over_sampling` provides a set of method to\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mperform over-sampling.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_random_over_sampler.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_X\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     23\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseOverSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRandomOverSampler\u001b[39;00m(BaseOverSampler):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Assuming X_train, X_test, y_train, y_test are your training and testing sets\n",
    "# Use the same preprocessor and classifier as before\n",
    "\n",
    "# Apply RandomOverSampler\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_train_resampled, y_train_resampled = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "# Define and fit the pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "# Evaluate on the test set\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Extract features (using TF-IDF as an example)\n",
    "vectorizer = TfidfVectorizer(max_features=5000)\n",
    "X = vectorizer.fit_transform(df['Review'])\n",
    "\n",
    "# Convert feature names to strings\n",
    "feature_names = [str(i) for i in range(X.shape[1])]\n",
    "\n",
    "# Update the feature names of the sparse matrix\n",
    "X = pd.DataFrame(X.toarray(), columns=feature_names)\n",
    "\n",
    "# Initialize the sentiment intensity analyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Extract sentiment features\n",
    "df['Sentiment'] = df['Review'].apply(lambda x: sia.polarity_scores(x)['compound'])\n",
    "\n",
    "# Combine text features with sentiment features\n",
    "X_combined = pd.concat([X, df['Sentiment']], axis=1)\n",
    "\n",
    "# Convert column names to strings\n",
    "X_combined.columns = X_combined.columns.astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 55.51%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have a 'Sentiment_Category' column in your DataFrame for classification\n",
    "df = df.dropna(subset=['Sentiment_Category'])  # Drop rows with missing target labels\n",
    "y = df['Sentiment_Category']\n",
    "\n",
    "# Extract sentiment scores as features\n",
    "X_combined = df[['Sentiment']]\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_combined, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize a Random Forest Classifier (you can replace this with your preferred model)\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 62.66%\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with 'Review', 'Rating', and 'Sentiment_Category' columns\n",
    "\n",
    "# Combine text features and rating\n",
    "df['Combined_Features'] = df['Review'] + ' ' + df['Rating'].astype(str)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['Review', 'Rating']], df['Sentiment_Category'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define a preprocessor with separate transformers for text and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=5000), 'Review'),\n",
    "        ('rating', 'passthrough', ['Rating'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Combine the preprocessor with a classifier in a pipeline\n",
    "classifier = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Train the model\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model Accuracy: 69.10%\n",
      "Best Parameters: {'classifier__n_estimators': 200, 'preprocessor__text__max_features': 1000}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# Assuming you have a DataFrame 'df' with 'Review', 'Rating', and 'Sentiment_Category' columns\n",
    "\n",
    "# Combine text features and rating\n",
    "df['Combined_Features'] = df['Review'] + ' ' + df['Rating'].astype(str)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    df[['Review', 'Rating']], df['Sentiment_Category'], test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Define a preprocessor with separate transformers for text and numerical data\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=5000), 'Review'),\n",
    "        ('rating', 'passthrough', ['Rating'])\n",
    "    ],\n",
    "    remainder='drop'\n",
    ")\n",
    "\n",
    "# Combine the preprocessor with a classifier in a pipeline\n",
    "classifier = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Define the parameter grid for GridSearchCV\n",
    "param_grid = {\n",
    "    'preprocessor__text__max_features': [1000, 5000, 10000],\n",
    "    'classifier__n_estimators': [50, 100, 200]\n",
    "}\n",
    "\n",
    "# Use GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(classifier, param_grid, cv=5, scoring='accuracy')\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best model\n",
    "best_classifier = grid_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_classifier.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Best Model Accuracy: {accuracy:.2%}\")\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (1.3.2)\n",
      "Requirement already satisfied: numpy<2.0,>=1.17.3 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.10.1)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from scikit-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from scikit-learn) (2.2.0)\n",
      "Requirement already satisfied: imbalanced-learn in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (0.11.0)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.3.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/navyaprasad/anaconda3/lib/python3.11/site-packages (from imbalanced-learn) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade scikit-learn\n",
    "!pip install --upgrade imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[255], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomUnderSampler\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mimblearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/__init__.py:52\u001b[0m\n\u001b[1;32m     48\u001b[0m     sys\u001b[38;5;241m.\u001b[39mstderr\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPartial import of imblearn during the build process.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;66;03m# We are not importing the rest of scikit-learn during the build\u001b[39;00m\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;66;03m# process, as it may not be compiled yet\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     53\u001b[0m         combine,\n\u001b[1;32m     54\u001b[0m         ensemble,\n\u001b[1;32m     55\u001b[0m         exceptions,\n\u001b[1;32m     56\u001b[0m         metrics,\n\u001b[1;32m     57\u001b[0m         over_sampling,\n\u001b[1;32m     58\u001b[0m         pipeline,\n\u001b[1;32m     59\u001b[0m         tensorflow,\n\u001b[1;32m     60\u001b[0m         under_sampling,\n\u001b[1;32m     61\u001b[0m         utils,\n\u001b[1;32m     62\u001b[0m     )\n\u001b[1;32m     63\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_version\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m __version__\n\u001b[1;32m     64\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FunctionSampler\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/__init__.py:5\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"The :mod:`imblearn.combine` provides methods which combine\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mover-sampling and under-sampling.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_enn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTEENN\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote_tomek\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTETomek\n\u001b[1;32m      8\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEENN\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTETomek\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/combine/_smote_enn.py:13\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m check_X_y\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseSampler\n\u001b[0;32m---> 13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mover_sampling\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01munder_sampling\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EditedNearestNeighbours\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/__init__.py:7\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mThe :mod:`imblearn.over_sampling` provides a set of method to\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03mperform over-sampling.\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_adasyn\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ADASYN\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_random_over_sampler\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RandomOverSampler\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_smote\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SMOTE, SMOTEN, SMOTENC, SVMSMOTE, BorderlineSMOTE, KMeansSMOTE\n\u001b[1;32m     10\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mADASYN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRandomOverSampler\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSMOTEN\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/imblearn/over_sampling/_random_over_sampler.py:18\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_docstring\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _random_state_docstring\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_param_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Interval\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_validation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _check_X\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseOverSampler\n\u001b[1;32m     22\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\n\u001b[1;32m     23\u001b[0m     sampling_strategy\u001b[38;5;241m=\u001b[39mBaseOverSampler\u001b[38;5;241m.\u001b[39m_sampling_strategy_docstring,\n\u001b[1;32m     24\u001b[0m     random_state\u001b[38;5;241m=\u001b[39m_random_state_docstring,\n\u001b[1;32m     25\u001b[0m )\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mRandomOverSampler\u001b[39;00m(BaseOverSampler):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name '_check_X' from 'imblearn.utils._validation' (/Users/navyaprasad/anaconda3/lib/python3.11/site-packages/imblearn/utils/_validation.py)"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming you have already loaded and preprocessed your data into X and y\n",
    "# X should contain your features, and y should contain the target variable\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define a preprocessor with a text transformer (e.g., TfidfVectorizer) and a resampler\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('text', TfidfVectorizer(max_features=5000), 'Review'),\n",
    "    ],\n",
    "    remainder='passthrough'\n",
    ")\n",
    "\n",
    "# Define the RandomOverSampler and RandomUnderSampler\n",
    "over_sampler = RandomOverSampler(sampling_strategy='auto', random_state=42)\n",
    "under_sampler = RandomUnderSampler(sampling_strategy='auto', random_state=42)\n",
    "\n",
    "# Define the classifier (you can replace this with your preferred model)\n",
    "classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Create an imbalanced-learn pipeline with resampling\n",
    "pipeline = Pipeline([\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('over_sampler', over_sampler),\n",
    "    ('under_sampler', under_sampler),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "# Fit the pipeline on the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "# Evaluate the accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Balanced Model Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 190,
     "status": "ok",
     "timestamp": 1702638641702,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "jgBQuQdWKnnv",
    "outputId": "b226065a-e5d9-4163-8e7b-de02179663d2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Sentiment_Category\n",
       "0  One of the most anticipated films of the year ...           Positive\n",
       "1  You'll have to have your wits about you and yo...    Strong Positive\n",
       "2  I'm a big fan of Nolan's work so was really lo...            Neutral\n",
       "3  \"Oppenheimer\" is a biographical thriller film ...    Strong Positive\n",
       "4  This movie is just... wow! I don't think I hav...    Strong Positive"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "selected_columns = ['Review', 'Sentiment_Category']\n",
    "\n",
    "# Create a new DataFrame with selected columns\n",
    "data = df[selected_columns]\n",
    "\n",
    "# Display the new DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 188,
     "status": "ok",
     "timestamp": 1702638644334,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "VyBqnpKkK6mA",
    "outputId": "516b8b4d-d200-444d-983d-f370b303d6b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 3495 entries, 0 to 3536\n",
      "Data columns (total 2 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Review              3495 non-null   object\n",
      " 1   Sentiment_Category  3495 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 211.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 224,
     "status": "ok",
     "timestamp": 1702638654025,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "qlrckT8GK6o1",
    "outputId": "949b0a61-8f7b-4e8c-8976-028c382174db"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Strong Positive    1465\n",
       "Neutral             807\n",
       "Positive            623\n",
       "Strong Negative     319\n",
       "Negative            281\n",
       "Name: Sentiment_Category, dtype: int64"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment_Category.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.9741    14\n",
       " 0.9975    11\n",
       " 0.9974    11\n",
       " 0.9934    11\n",
       " 0.9954    10\n",
       "           ..\n",
       " 0.9325     1\n",
       "-0.6369     1\n",
       "-0.9642     1\n",
       " 0.8972     1\n",
       "-0.5562     1\n",
       "Name: Sentiment, Length: 1994, dtype: int64"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.Sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 796
    },
    "executionInfo": {
     "elapsed": 196,
     "status": "ok",
     "timestamp": 1702638666173,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "wUWAgBZDK6tX",
    "outputId": "7049e129-359b-4ef1-ec72-03073189a049"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2048137990.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Sentiment_Category.replace('strong positive',2,inplace=True)\n",
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2048137990.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Sentiment_Category.replace('positive',1,inplace=True)\n",
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2048137990.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Sentiment_Category.replace('neutral',0,inplace=True)\n",
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2048137990.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Sentiment_Category.replace('negative',-1,inplace=True)\n",
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2048137990.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Sentiment_Category.replace('strong negative',-2,inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the most anticipated films of the year ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>You'll have to have your wits about you and yo...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'm a big fan of Nolan's work so was really lo...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"Oppenheimer\" is a biographical thriller film ...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>This movie is just... wow! I don't think I hav...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I was familiar with the Manhattan project and ...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>I may consider myself lucky to be alive to wat...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>I'm still collecting my thoughts after experie...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Is it just me or did anyone else find this mov...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Okay, Nolan fans, get your fingers poised to d...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Sentiment_Category\n",
       "0  One of the most anticipated films of the year ...           Positive\n",
       "1  You'll have to have your wits about you and yo...    Strong Positive\n",
       "2  I'm a big fan of Nolan's work so was really lo...            Neutral\n",
       "3  \"Oppenheimer\" is a biographical thriller film ...    Strong Positive\n",
       "4  This movie is just... wow! I don't think I hav...    Strong Positive\n",
       "5  I was familiar with the Manhattan project and ...           Positive\n",
       "6  I may consider myself lucky to be alive to wat...    Strong Positive\n",
       "7  I'm still collecting my thoughts after experie...    Strong Positive\n",
       "8  Is it just me or did anyone else find this mov...           Positive\n",
       "9  Okay, Nolan fans, get your fingers poised to d...            Neutral"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Sentiment_Category.replace('strong positive',2,inplace=True)\n",
    "data.Sentiment_Category.replace('positive',1,inplace=True)\n",
    "data.Sentiment_Category.replace('neutral',0,inplace=True)\n",
    "data.Sentiment_Category.replace('negative',-1,inplace=True)\n",
    "data.Sentiment_Category.replace('strong negative',-2,inplace=True)\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "executionInfo": {
     "elapsed": 292,
     "status": "ok",
     "timestamp": 1702638676959,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "iCpwQJDFLD_O",
    "outputId": "b5978c47-e850-42fd-b1aa-3faf052b76ae"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"One of the most anticipated films of the year for many people, myself included, Oppenheimer largely delivers. Much of it's great. I feel like I loved two of its three hours, and liked the other hour.... but it's that fact that stops me from adoring the entire thing. I know with Christopher Nolan's Dunkirk, that clicked on a second watch, so maybe Oppenheimer will need one too. That being said, I don't feel the need to rush out and see it again too soon, because it was a long and exhausting film.But in many ways, I can't deny it was an exceptionally well made one. It looks and sounds as amazing as you'd expect, feeling as though it accurately captures the time period it's set in, and containing amazing sound design and one of the year's best scores so far. Every performance is good to great, but the film belongs to Cillian Murphy, and I feel like he's the lead actor to beat at this stage, if we're talking (early) awards consideration.The film's at its best when it focuses on being a psychological thriller featuring a famous historical figure, and at one point, it even turns into a psychological horror film. There's one sequence in here involving a speech that's particularly terrifying. It also manages to have some very suspenseful moments, even though its story is commonly known history at this point.I did really feel the length in the final hour, though, and maybe I wish that final act had been more of an extended epilogue, rather than a whole third of the movie. I currently feel as though I would've loved Oppenheimer more had it been 2.5 hours instead of 3, but nothing about it was bad by any means; just a little patience testing (this is very subjective - I remember feeling like the similarly long Babylon totally justified its runtime, though others didn't feel that way).I'm left feeling like I watched a film that wasn't a slam dunk, but was incredible for more of its runtime than it wasn't. And that's still worth celebrating, and makes Oppenheimer worth seeing in cinemas for sure.\""
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1702638683438,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "g1yHn-yNLGmW",
    "outputId": "8805d056-03bc-4943-8fe9-d06baa6efb97"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/706651797.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Review = data.Review.apply(clean)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"One of the most anticipated films of the year for many people, myself included, Oppenheimer largely delivers. Much of it's great. I feel like I loved two of its three hours, and liked the other hour.... but it's that fact that stops me from adoring the entire thing. I know with Christopher Nolan's Dunkirk, that clicked on a second watch, so maybe Oppenheimer will need one too. That being said, I don't feel the need to rush out and see it again too soon, because it was a long and exhausting film.But in many ways, I can't deny it was an exceptionally well made one. It looks and sounds as amazing as you'd expect, feeling as though it accurately captures the time period it's set in, and containing amazing sound design and one of the year's best scores so far. Every performance is good to great, but the film belongs to Cillian Murphy, and I feel like he's the lead actor to beat at this stage, if we're talking (early) awards consideration.The film's at its best when it focuses on being a psychological thriller featuring a famous historical figure, and at one point, it even turns into a psychological horror film. There's one sequence in here involving a speech that's particularly terrifying. It also manages to have some very suspenseful moments, even though its story is commonly known history at this point.I did really feel the length in the final hour, though, and maybe I wish that final act had been more of an extended epilogue, rather than a whole third of the movie. I currently feel as though I would've loved Oppenheimer more had it been 2.5 hours instead of 3, but nothing about it was bad by any means; just a little patience testing (this is very subjective - I remember feeling like the similarly long Babylon totally justified its runtime, though others didn't feel that way).I'm left feeling like I watched a film that wasn't a slam dunk, but was incredible for more of its runtime than it wasn't. And that's still worth celebrating, and makes Oppenheimer worth seeing in cinemas for sure.\""
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clean(text):\n",
    "    cleaned = re.compile(r'<.*?>')\n",
    "    return re.sub(cleaned,'',text)\n",
    "\n",
    "data.Review = data.Review.apply(clean)\n",
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "executionInfo": {
     "elapsed": 203,
     "status": "ok",
     "timestamp": 1702638689863,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "3RZ1UzqDLINk"
   },
   "outputs": [],
   "source": [
    "def is_special(text):\n",
    "    rem = ''\n",
    "    for i in text:\n",
    "        if i.isalnum():\n",
    "            rem = rem + i\n",
    "        else:\n",
    "            rem = rem + ' '\n",
    "    return rem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 905,
     "status": "ok",
     "timestamp": 1702638696254,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "5I0wlrTSLJvb",
    "outputId": "ec62268f-2419-40bc-f5ec-acb0f0dd9855"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/543257354.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Review = data.Review.apply(is_special)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'One of the most anticipated films of the year for many people  myself included  Oppenheimer largely delivers  Much of it s great  I feel like I loved two of its three hours  and liked the other hour     but it s that fact that stops me from adoring the entire thing  I know with Christopher Nolan s Dunkirk  that clicked on a second watch  so maybe Oppenheimer will need one too  That being said  I don t feel the need to rush out and see it again too soon  because it was a long and exhausting film But in many ways  I can t deny it was an exceptionally well made one  It looks and sounds as amazing as you d expect  feeling as though it accurately captures the time period it s set in  and containing amazing sound design and one of the year s best scores so far  Every performance is good to great  but the film belongs to Cillian Murphy  and I feel like he s the lead actor to beat at this stage  if we re talking  early  awards consideration The film s at its best when it focuses on being a psychological thriller featuring a famous historical figure  and at one point  it even turns into a psychological horror film  There s one sequence in here involving a speech that s particularly terrifying  It also manages to have some very suspenseful moments  even though its story is commonly known history at this point I did really feel the length in the final hour  though  and maybe I wish that final act had been more of an extended epilogue  rather than a whole third of the movie  I currently feel as though I would ve loved Oppenheimer more had it been 2 5 hours instead of 3  but nothing about it was bad by any means  just a little patience testing  this is very subjective   I remember feeling like the similarly long Babylon totally justified its runtime  though others didn t feel that way  I m left feeling like I watched a film that wasn t a slam dunk  but was incredible for more of its runtime than it wasn t  And that s still worth celebrating  and makes Oppenheimer worth seeing in cinemas for sure '"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Review = data.Review.apply(is_special)\n",
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1702638702634,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "AvytBwd-LLIG",
    "outputId": "ab687247-28bb-4213-a2f2-117eeda8ee73"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/2527616974.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Review = data.Review.apply(to_lower)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one of the most anticipated films of the year for many people  myself included  oppenheimer largely delivers  much of it s great  i feel like i loved two of its three hours  and liked the other hour     but it s that fact that stops me from adoring the entire thing  i know with christopher nolan s dunkirk  that clicked on a second watch  so maybe oppenheimer will need one too  that being said  i don t feel the need to rush out and see it again too soon  because it was a long and exhausting film but in many ways  i can t deny it was an exceptionally well made one  it looks and sounds as amazing as you d expect  feeling as though it accurately captures the time period it s set in  and containing amazing sound design and one of the year s best scores so far  every performance is good to great  but the film belongs to cillian murphy  and i feel like he s the lead actor to beat at this stage  if we re talking  early  awards consideration the film s at its best when it focuses on being a psychological thriller featuring a famous historical figure  and at one point  it even turns into a psychological horror film  there s one sequence in here involving a speech that s particularly terrifying  it also manages to have some very suspenseful moments  even though its story is commonly known history at this point i did really feel the length in the final hour  though  and maybe i wish that final act had been more of an extended epilogue  rather than a whole third of the movie  i currently feel as though i would ve loved oppenheimer more had it been 2 5 hours instead of 3  but nothing about it was bad by any means  just a little patience testing  this is very subjective   i remember feeling like the similarly long babylon totally justified its runtime  though others didn t feel that way  i m left feeling like i watched a film that wasn t a slam dunk  but was incredible for more of its runtime than it wasn t  and that s still worth celebrating  and makes oppenheimer worth seeing in cinemas for sure '"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def to_lower(text):\n",
    "    return text.lower()\n",
    "\n",
    "data.Review = data.Review.apply(to_lower)\n",
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 852,
     "status": "ok",
     "timestamp": 1702638710885,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "IQaQhkXiLM1h",
    "outputId": "305ff41e-112f-4aef-d654-677e4bd1d299"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/navyaprasad/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     /Users/navyaprasad/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4270,
     "status": "ok",
     "timestamp": 1702638721922,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "z931cSy-LOvj",
    "outputId": "0a1ab0a9-838b-4035-d62d-e3031bc94155"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/3346730211.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Review = data.Review.apply(rem_stopwords)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['one',\n",
       " 'anticipated',\n",
       " 'films',\n",
       " 'year',\n",
       " 'many',\n",
       " 'people',\n",
       " 'included',\n",
       " 'oppenheimer',\n",
       " 'largely',\n",
       " 'delivers',\n",
       " 'much',\n",
       " 'great',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'loved',\n",
       " 'two',\n",
       " 'three',\n",
       " 'hours',\n",
       " 'liked',\n",
       " 'hour',\n",
       " 'fact',\n",
       " 'stops',\n",
       " 'adoring',\n",
       " 'entire',\n",
       " 'thing',\n",
       " 'know',\n",
       " 'christopher',\n",
       " 'nolan',\n",
       " 'dunkirk',\n",
       " 'clicked',\n",
       " 'second',\n",
       " 'watch',\n",
       " 'maybe',\n",
       " 'oppenheimer',\n",
       " 'need',\n",
       " 'one',\n",
       " 'said',\n",
       " 'feel',\n",
       " 'need',\n",
       " 'rush',\n",
       " 'see',\n",
       " 'soon',\n",
       " 'long',\n",
       " 'exhausting',\n",
       " 'film',\n",
       " 'many',\n",
       " 'ways',\n",
       " 'deny',\n",
       " 'exceptionally',\n",
       " 'well',\n",
       " 'made',\n",
       " 'one',\n",
       " 'looks',\n",
       " 'sounds',\n",
       " 'amazing',\n",
       " 'expect',\n",
       " 'feeling',\n",
       " 'though',\n",
       " 'accurately',\n",
       " 'captures',\n",
       " 'time',\n",
       " 'period',\n",
       " 'set',\n",
       " 'containing',\n",
       " 'amazing',\n",
       " 'sound',\n",
       " 'design',\n",
       " 'one',\n",
       " 'year',\n",
       " 'best',\n",
       " 'scores',\n",
       " 'far',\n",
       " 'every',\n",
       " 'performance',\n",
       " 'good',\n",
       " 'great',\n",
       " 'film',\n",
       " 'belongs',\n",
       " 'cillian',\n",
       " 'murphy',\n",
       " 'feel',\n",
       " 'like',\n",
       " 'lead',\n",
       " 'actor',\n",
       " 'beat',\n",
       " 'stage',\n",
       " 'talking',\n",
       " 'early',\n",
       " 'awards',\n",
       " 'consideration',\n",
       " 'film',\n",
       " 'best',\n",
       " 'focuses',\n",
       " 'psychological',\n",
       " 'thriller',\n",
       " 'featuring',\n",
       " 'famous',\n",
       " 'historical',\n",
       " 'figure',\n",
       " 'one',\n",
       " 'point',\n",
       " 'even',\n",
       " 'turns',\n",
       " 'psychological',\n",
       " 'horror',\n",
       " 'film',\n",
       " 'one',\n",
       " 'sequence',\n",
       " 'involving',\n",
       " 'speech',\n",
       " 'particularly',\n",
       " 'terrifying',\n",
       " 'also',\n",
       " 'manages',\n",
       " 'suspenseful',\n",
       " 'moments',\n",
       " 'even',\n",
       " 'though',\n",
       " 'story',\n",
       " 'commonly',\n",
       " 'known',\n",
       " 'history',\n",
       " 'point',\n",
       " 'really',\n",
       " 'feel',\n",
       " 'length',\n",
       " 'final',\n",
       " 'hour',\n",
       " 'though',\n",
       " 'maybe',\n",
       " 'wish',\n",
       " 'final',\n",
       " 'act',\n",
       " 'extended',\n",
       " 'epilogue',\n",
       " 'rather',\n",
       " 'whole',\n",
       " 'third',\n",
       " 'movie',\n",
       " 'currently',\n",
       " 'feel',\n",
       " 'though',\n",
       " 'would',\n",
       " 'loved',\n",
       " 'oppenheimer',\n",
       " '2',\n",
       " '5',\n",
       " 'hours',\n",
       " 'instead',\n",
       " '3',\n",
       " 'nothing',\n",
       " 'bad',\n",
       " 'means',\n",
       " 'little',\n",
       " 'patience',\n",
       " 'testing',\n",
       " 'subjective',\n",
       " 'remember',\n",
       " 'feeling',\n",
       " 'like',\n",
       " 'similarly',\n",
       " 'long',\n",
       " 'babylon',\n",
       " 'totally',\n",
       " 'justified',\n",
       " 'runtime',\n",
       " 'though',\n",
       " 'others',\n",
       " 'feel',\n",
       " 'way',\n",
       " 'left',\n",
       " 'feeling',\n",
       " 'like',\n",
       " 'watched',\n",
       " 'film',\n",
       " 'slam',\n",
       " 'dunk',\n",
       " 'incredible',\n",
       " 'runtime',\n",
       " 'still',\n",
       " 'worth',\n",
       " 'celebrating',\n",
       " 'makes',\n",
       " 'oppenheimer',\n",
       " 'worth',\n",
       " 'seeing',\n",
       " 'cinemas',\n",
       " 'sure']"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def rem_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = word_tokenize(text)\n",
    "    return [w for w in words if w not in stop_words]\n",
    "\n",
    "data.Review = data.Review.apply(rem_stopwords)\n",
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "executionInfo": {
     "elapsed": 8296,
     "status": "ok",
     "timestamp": 1702638742740,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "B-WvXI8_LQm5",
    "outputId": "50939341-f18d-4cec-e7a1-b06662927827"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/l0/2psbd05152j5n5116yzg2lyc0000gn/T/ipykernel_25782/592623717.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data.Review = data.Review.apply(stem_txt)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'one anticip film year mani peopl includ oppenheim larg deliv much great feel like love two three hour like hour fact stop ador entir thing know christoph nolan dunkirk click second watch mayb oppenheim need one said feel need rush see soon long exhaust film mani way deni except well made one look sound amaz expect feel though accur captur time period set contain amaz sound design one year best score far everi perform good great film belong cillian murphi feel like lead actor beat stage talk earli award consider film best focus psycholog thriller featur famous histor figur one point even turn psycholog horror film one sequenc involv speech particular terrifi also manag suspens moment even though stori common known histori point realli feel length final hour though mayb wish final act extend epilogu rather whole third movi current feel though would love oppenheim 2 5 hour instead 3 noth bad mean littl patienc test subject rememb feel like similar long babylon total justifi runtim though other feel way left feel like watch film slam dunk incred runtim still worth celebr make oppenheim worth see cinema sure'"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def stem_txt(text):\n",
    "    ss = SnowballStemmer('english')\n",
    "    return \" \".join([ss.stem(w) for w in text])\n",
    "\n",
    "data.Review = data.Review.apply(stem_txt)\n",
    "data.Review[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 200,
     "status": "ok",
     "timestamp": 1702638745186,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "d8NhsiNtLUs-",
    "outputId": "b1e990b9-1128-409d-a4c4-7d172bca8b13"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Review</th>\n",
       "      <th>Sentiment_Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>one anticip film year mani peopl includ oppenh...</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>wit brain fulli switch watch oppenheim could e...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>big fan nolan work realli look forward underst...</td>\n",
       "      <td>Neutral</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oppenheim biograph thriller film written direc...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>movi wow think ever felt like watch movi like ...</td>\n",
       "      <td>Strong Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Review Sentiment_Category\n",
       "0  one anticip film year mani peopl includ oppenh...           Positive\n",
       "1  wit brain fulli switch watch oppenheim could e...    Strong Positive\n",
       "2  big fan nolan work realli look forward underst...            Neutral\n",
       "3  oppenheim biograph thriller film written direc...    Strong Positive\n",
       "4  movi wow think ever felt like watch movi like ...    Strong Positive"
      ]
     },
     "execution_count": 244,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1726,
     "status": "ok",
     "timestamp": 1702638753334,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "lLHFoJXuLXP-",
    "outputId": "c8e08e21-ea68-4b58-b03f-e1c4733df38e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X.shape =  (3495, 1000)\n",
      "y.shape =  (3495,)\n"
     ]
    }
   ],
   "source": [
    "X = np.array(data.iloc[:,0].values)\n",
    "y = np.array(data.Sentiment_Category.values)\n",
    "cv = CountVectorizer(max_features = 1000)\n",
    "X = cv.fit_transform(data.Review).toarray()\n",
    "print(\"X.shape = \",X.shape)\n",
    "print(\"y.shape = \",y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 183,
     "status": "ok",
     "timestamp": 1702638758673,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "DXpfLMx9LY3D",
    "outputId": "fecd6bc5-3125-4645-c58b-3fddc948cfa8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 199,
     "status": "ok",
     "timestamp": 1702638767453,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "JySOlEW-LajU",
    "outputId": "71f70c7b-6b36-48f5-a5ad-f2e06f595750"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shapes : X = (2796, 1000), y = (2796,)\n",
      "Test shapes : X = (699, 1000), y = (699,)\n"
     ]
    }
   ],
   "source": [
    "trainx,testx,trainy,testy = train_test_split(X,y,test_size=0.2,random_state=9)\n",
    "print(\"Train shapes : X = {}, y = {}\".format(trainx.shape,trainy.shape))\n",
    "print(\"Test shapes : X = {}, y = {}\".format(testx.shape,testy.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 74
    },
    "executionInfo": {
     "elapsed": 475,
     "status": "ok",
     "timestamp": 1702638776127,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "5DZPU6AJLcr0",
    "outputId": "aca60643-5a3c-4088-b492-fba0bb8cf87a"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>BernoulliNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">BernoulliNB</label><div class=\"sk-toggleable__content\"><pre>BernoulliNB()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "BernoulliNB()"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb,mnb,bnb = GaussianNB(),MultinomialNB(alpha=1.0,fit_prior=True),BernoulliNB(alpha=1.0,fit_prior=True)\n",
    "gnb.fit(trainx,trainy)\n",
    "mnb.fit(trainx,trainy)\n",
    "bnb.fit(trainx,trainy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 193,
     "status": "ok",
     "timestamp": 1702638787521,
     "user": {
      "displayName": "Jagrati Chauhan",
      "userId": "09206189041048891570"
     },
     "user_tz": 420
    },
    "id": "9f8knYY3LevU",
    "outputId": "0c5f3005-e8e6-4041-cb7d-8ddd53fb8e7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gaussian =  0.31616595135908443\n",
      "Multinomial =  0.5393419170243204\n",
      "Bernoulli =  0.4563662374821173\n"
     ]
    }
   ],
   "source": [
    "ypg = gnb.predict(testx)\n",
    "ypm = mnb.predict(testx)\n",
    "ypb = bnb.predict(testx)\n",
    "\n",
    "print(\"Gaussian = \",accuracy_score(testy,ypg))\n",
    "print(\"Multinomial = \",accuracy_score(testy,ypm))\n",
    "print(\"Bernoulli = \",accuracy_score(testy,ypb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Jlu-iyNLhmC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOuFZk2CoM6OyFCd6I3fq3V",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
